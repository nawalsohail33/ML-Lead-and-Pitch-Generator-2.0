{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8670829e-e264-4d93-89a5-2aa91670314c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"C:/Users/HP/Desktop/data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97e65967-5e44-48c3-931e-73e60115874c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-docx\n",
      "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from python-docx) (5.2.1)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from python-docx) (4.11.0)\n",
      "Downloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
      "Installing collected packages: python-docx\n",
      "Successfully installed python-docx-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3569be74-50e0-4600-acf3-b2d5c564046f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Load environment variables and configure Gemini\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "# Load datasets\n",
    "df = pd.read_csv('C:/Users/HP/Desktop/data.csv')\n",
    "new_df = pd.read_excel(\"C:/Users/HP/Downloads/WYRDEX EMAIL CMPAIGN.xlsx\")\n",
    "\n",
    "def combine_text(row):\n",
    "    activity_raw = str(row['activity'])\n",
    "    activity_clean = activity_raw.replace('\\\\', '')\n",
    "    try:\n",
    "        activity_list = ast.literal_eval(activity_clean)\n",
    "        activity_text = \" \".join(activity_list)\n",
    "    except Exception:\n",
    "        activity_text = activity_clean\n",
    "    combined = (\n",
    "        f\"{row['name']} {row['organizational form_description']} \"\n",
    "        f\"{row['nutrition code1_description']} {activity_text}\"\n",
    "    )\n",
    "    return combined\n",
    "\n",
    "df['combined_text'] = df.apply(combine_text, axis=1)\n",
    "\n",
    "print(\"Loading Sentence-BERT model...\")\n",
    "model_bert = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "print(\"Encoding company data...\")\n",
    "company_embeddings = model_bert.encode(df['combined_text'].tolist(), convert_to_tensor=True)\n",
    "\n",
    "user_query = input(\"Describe your service or requirement: \")\n",
    "query_embedding = model_bert.encode(user_query, convert_to_tensor=True)\n",
    "\n",
    "scores = torch.nn.functional.cosine_similarity(query_embedding.unsqueeze(0), company_embeddings)\n",
    "\n",
    "top_k = int(input(\"Enter number of companies you want to pitch\"))\n",
    "top_results = torch.topk(scores, k=top_k)\n",
    "\n",
    "def reason_for_selection(similarity, activity):\n",
    "    percent = similarity * 100\n",
    "    if percent > 80:\n",
    "        level = \"very high\"\n",
    "    elif percent > 60:\n",
    "        level = \"high\"\n",
    "    elif percent > 40:\n",
    "        level = \"moderate\"\n",
    "    else:\n",
    "        level = \"low\"\n",
    "    return (f\"This company was selected because it has a {level} semantic similarity \"\n",
    "            f\"({percent:.2f}%) with your service description, particularly matching areas such as: '{activity}'.\")\n",
    "\n",
    "def prompt_generator(user_input, row):\n",
    "    prompt = \"\"\"\n",
    "You are an AI business pitch assistant.\n",
    "\n",
    "A user is offering the following service: ,user_service,.\n",
    "\n",
    "One potential client is a company named ,name, that does the following: ,activity,.\n",
    "\n",
    "Generate a short, compelling pitch of 4‚Äì5 sentences to explain how the user's service can benefit this company. Make it personalized, professional, and persuasive.\n",
    "\"\"\"\n",
    "    prompt = prompt.replace(\",user_service,\", user_input)\n",
    "    prompt = prompt.replace(\",name,\", row['name'])\n",
    "    prompt = prompt.replace(\",activity,\", row['activity'])\n",
    "    return prompt\n",
    "\n",
    "# Instantiate Gemini model\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "print(f\"\\nTop {top_k} matching companies with pitches:\\n\")\n",
    "\n",
    "for score, idx in zip(top_results.values, top_results.indices):\n",
    "    idx_int = idx.item()\n",
    "    row = df.iloc[idx_int]\n",
    "\n",
    "    email_rows = new_df[new_df['NAME'].str.lower() == row['name'].lower()]\n",
    "    company_email = email_rows.iloc[0]['EMAIL'] if not email_rows.empty else \"Email not found\"\n",
    "\n",
    "    similarity = score.item()\n",
    "    reason = reason_for_selection(similarity, row['activity'])\n",
    "\n",
    "    prompt = prompt_generator(user_query, row)\n",
    "\n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        pitch_text = response.text.strip()\n",
    "    except Exception as e:\n",
    "        pitch_text = f\"Error generating pitch: {e}\"\n",
    "\n",
    "    print(f\"üîπ Company: {row['name']}\")\n",
    "    print(f\"üìß Email: {company_email}\")\n",
    "    print(f\"üìä Similarity Score: {similarity:.4f}\")\n",
    "    print(f\"üí° Reason for Selection: {reason}\")\n",
    "    print(f\"üìù Pitch:\\n{pitch_text}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca77b4c-982b-4efa-87f8-c3227c338de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Load environment variables and configure Gemini\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "# Load datasets\n",
    "df = pd.read_csv('C:/Users/HP/Desktop/data.csv')\n",
    "new_df = pd.read_excel(\"C:/Users/HP/Downloads/WYRDEX EMAIL CMPAIGN.xlsx\")\n",
    "\n",
    "def combine_text(row):\n",
    "    activity_raw = str(row['activity'])\n",
    "    activity_clean = activity_raw.replace('\\\\', '')\n",
    "    try:\n",
    "        activity_list = ast.literal_eval(activity_clean)\n",
    "        activity_text = \" \".join(activity_list)\n",
    "    except Exception:\n",
    "        activity_text = activity_clean\n",
    "    combined = (\n",
    "        f\"{row['name']} {row['organizational form_description']} \"\n",
    "        f\"{row['nutrition code1_description']} {activity_text}\"\n",
    "    )\n",
    "    return combined\n",
    "\n",
    "df['combined_text'] = df.apply(combine_text, axis=1)\n",
    "\n",
    "print(\"Loading Sentence-BERT model...\")\n",
    "model_bert = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "print(\"Encoding company data...\")\n",
    "company_embeddings = model_bert.encode(df['combined_text'].tolist(), convert_to_tensor=True)\n",
    "\n",
    "user_query = input(\"Describe your service or requirement: \")\n",
    "query_embedding = model_bert.encode(user_query, convert_to_tensor=True)\n",
    "\n",
    "scores = torch.nn.functional.cosine_similarity(query_embedding.unsqueeze(0), company_embeddings)\n",
    "\n",
    "top_k = int(input(\"Enter number of companies you want to pitch\"))\n",
    "top_results = torch.topk(scores, k=top_k)\n",
    "\n",
    "def reason_for_selection(similarity, activity):\n",
    "    percent = similarity * 100\n",
    "    if percent > 80:\n",
    "        level = \"very high\"\n",
    "    elif percent > 60:\n",
    "        level = \"high\"\n",
    "    elif percent > 40:\n",
    "        level = \"moderate\"\n",
    "    else:\n",
    "        level = \"low\"\n",
    "    return (f\"This company was selected because it has a {level} semantic similarity \"\n",
    "            f\"({percent:.2f}%) with your service description, particularly matching areas such as: '{activity}'.\")\n",
    "\n",
    "def prompt_generator(user_input, row):\n",
    "    prompt = \"\"\"\n",
    "You are an AI business pitch assistant.\n",
    "\n",
    "A user is offering the following service: ,user_service,.\n",
    "\n",
    "One potential client is a company named ,name, that does the following: ,activity,.\n",
    "\n",
    "Generate a short, compelling pitch of 4‚Äì5 sentences to explain how the user's service can benefit this company. Make it personalized, professional, and persuasive.\n",
    "\"\"\"\n",
    "    prompt = prompt.replace(\",user_service,\", user_input)\n",
    "    prompt = prompt.replace(\",name,\", row['name'])\n",
    "    prompt = prompt.replace(\",activity,\", row['activity'])\n",
    "    return prompt\n",
    "\n",
    "# Instantiate Gemini model\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "# List to store pitch data for Excel\n",
    "pitch_records = []\n",
    "\n",
    "print(f\"\\nTop {top_k} matching companies with pitches:\\n\")\n",
    "\n",
    "for score, idx in zip(top_results.values, top_results.indices):\n",
    "    idx_int = idx.item()\n",
    "    row = df.iloc[idx_int]\n",
    "\n",
    "    email_rows = new_df[new_df['NAME'].str.lower() == row['name'].lower()]\n",
    "    company_email = email_rows.iloc[0]['EMAIL'] if not email_rows.empty else \"Email not found\"\n",
    "\n",
    "    similarity = score.item()\n",
    "    reason = reason_for_selection(similarity, row['activity'])\n",
    "\n",
    "    prompt = prompt_generator(user_query, row)\n",
    "\n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        pitch_text = response.text.strip()\n",
    "    except Exception as e:\n",
    "        pitch_text = f\"Error generating pitch: {e}\"\n",
    "\n",
    "    # Print to console\n",
    "    print(f\"üîπ Company: {row['name']}\")\n",
    "    print(f\"üìß Email: {company_email}\")\n",
    "    print(f\"üìä Similarity Score: {similarity:.4f}\")\n",
    "    print(f\"üí° Reason for Selection: {reason}\")\n",
    "    print(f\"üìù Pitch:\\n{pitch_text}\\n\")\n",
    "\n",
    "    # Save record for Excel\n",
    "    pitch_records.append({\n",
    "        \"Company Name\": row['name'],\n",
    "        \"Email\": company_email,\n",
    "        \"Activity/Description\": row['activity'],\n",
    "        \"Similarity Score\": similarity,\n",
    "        \"Pitch\": pitch_text\n",
    "    })\n",
    "\n",
    "# Create DataFrame for pitches and save to Excel\n",
    "pitch_df = pd.DataFrame(pitch_records)\n",
    "excel_filename = \"generated_pitches.xlsx\"\n",
    "pitch_df.to_excel(excel_filename, index=False)\n",
    "\n",
    "print(f\"Pitches saved to Excel file: {excel_filename}\")\n",
    "\n",
    "# Provide a download link in Jupyter\n",
    "display(FileLink(excel_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeda3ec7-5e3b-447e-b64c-e769794db9c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0ec1c9-0909-44fc-b4a0-648c80669c24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
